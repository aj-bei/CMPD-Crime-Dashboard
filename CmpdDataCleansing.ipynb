{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9970f8e-67c1-41cf-be87-652491f22090",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "83b3d8f5-b49c-4e2d-91eb-2fd9cf713676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "13a196bb-ce5d-493e-ba63-0b211643061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526b5d5f-d3fe-4cb7-a0ad-768e34d39471",
   "metadata": {},
   "source": [
    "# **Importing Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73cb3079-a790-48df-a044-025d0db26978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash import Output, Input, Dash\n",
    "import dash_bootstrap_components as dbc\n",
    "import plotly.express as px\n",
    "from urllib.request import urlopen\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.graph_objects as go\n",
    "import json\n",
    "import shapely\n",
    "from shapely.geometry import Point, Polygon\n",
    "from dash import State\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date, datetime, timedelta\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83f1aa63-6e67-4374-ade8-79f10032e21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_26444\\3129091874.py:1: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  masterDf = pd.read_csv('CMPD_Incidents2.csv')\n"
     ]
    }
   ],
   "source": [
    "masterDf = pd.read_csv('CMPD_Incidents2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "331705a7-6cb9-4ec9-8581-867e5790a6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>INCIDENT_REPORT_ID</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>X_COORD_PUBLIC</th>\n",
       "      <th>Y_COORD_PUBLIC</th>\n",
       "      <th>...</th>\n",
       "      <th>LOCATION_TYPE_DESCRIPTION</th>\n",
       "      <th>PLACE_TYPE_DESCRIPTION</th>\n",
       "      <th>PLACE_DETAIL_DESCRIPTION</th>\n",
       "      <th>CLEARANCE_STATUS</th>\n",
       "      <th>CLEARANCE_DETAIL_STATUS</th>\n",
       "      <th>CLEARANCE_DATE</th>\n",
       "      <th>HIGHEST_NIBRS_CODE</th>\n",
       "      <th>HIGHEST_NIBRS_DESCRIPTION</th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>GlobalID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.471035e+06</td>\n",
       "      <td>555315.000127</td>\n",
       "      <td>2023</td>\n",
       "      <td>20230610-1356-01</td>\n",
       "      <td>5700 N TRYON ST</td>\n",
       "      <td>CHARLOTTE</td>\n",
       "      <td>NC</td>\n",
       "      <td>28213</td>\n",
       "      <td>1471035</td>\n",
       "      <td>555315</td>\n",
       "      <td>...</td>\n",
       "      <td>Outdoors</td>\n",
       "      <td>Commercial Place</td>\n",
       "      <td>Other - Commercial Place</td>\n",
       "      <td>Open</td>\n",
       "      <td>Open</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240</td>\n",
       "      <td>Motor Vehicle Theft</td>\n",
       "      <td>1</td>\n",
       "      <td>{277CD4BD-6F2A-49D3-8351-6E020F77AE22}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              X              Y  YEAR INCIDENT_REPORT_ID         LOCATION  \\\n",
       "0  1.471035e+06  555315.000127  2023   20230610-1356-01  5700 N TRYON ST   \n",
       "\n",
       "        CITY STATE    ZIP  X_COORD_PUBLIC  Y_COORD_PUBLIC  ...  \\\n",
       "0  CHARLOTTE    NC  28213         1471035          555315  ...   \n",
       "\n",
       "   LOCATION_TYPE_DESCRIPTION  PLACE_TYPE_DESCRIPTION  \\\n",
       "0                   Outdoors        Commercial Place   \n",
       "\n",
       "   PLACE_DETAIL_DESCRIPTION CLEARANCE_STATUS  CLEARANCE_DETAIL_STATUS  \\\n",
       "0  Other - Commercial Place             Open                     Open   \n",
       "\n",
       "  CLEARANCE_DATE HIGHEST_NIBRS_CODE HIGHEST_NIBRS_DESCRIPTION OBJECTID  \\\n",
       "0            NaN                240       Motor Vehicle Theft        1   \n",
       "\n",
       "                                 GlobalID  \n",
       "0  {277CD4BD-6F2A-49D3-8351-6E020F77AE22}  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking amount of rows and columns in Dataframe\n",
    "\n",
    "masterDf.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "843ae996-a234-4536-b396-858491623b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Unessesary Columns \n",
    "\n",
    "DropColumns = ['X', 'Y', 'X_COORD_PUBLIC', 'Y_COORD_PUBLIC', 'CLEARANCE_DETAIL_STATUS', \n",
    "               'GlobalID', 'CITY', 'STATE','ADDRESS_DESCRIPTION', 'LOCATION_TYPE_DESCRIPTION']\n",
    "masterDf.drop(columns = DropColumns, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "037f5d2b-c432-4932-a39c-a1f4b8de38b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_REPORTED</th>\n",
       "      <th>DATE_INCIDENT_BEGAN</th>\n",
       "      <th>DATE_INCIDENT_END</th>\n",
       "      <th>CLEARANCE_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023/06/10</td>\n",
       "      <td>2023/06/10</td>\n",
       "      <td>2023/06/10</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023/06/15</td>\n",
       "      <td>2023/06/15</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021/10/01</td>\n",
       "      <td>2021/10/01</td>\n",
       "      <td>2021/10/01</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019/08/29</td>\n",
       "      <td>2019/08/19</td>\n",
       "      <td>2019/08/19</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022/12/05</td>\n",
       "      <td>2022/11/20</td>\n",
       "      <td>2022/11/20</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DATE_REPORTED DATE_INCIDENT_BEGAN DATE_INCIDENT_END CLEARANCE_DATE\n",
       "0    2023/06/10          2023/06/10        2023/06/10            nan\n",
       "1    2023/06/15          2023/06/15               nan            nan\n",
       "2    2021/10/01          2021/10/01        2021/10/01            nan\n",
       "3    2019/08/29          2019/08/19        2019/08/19            nan\n",
       "4    2022/12/05          2022/11/20        2022/11/20            nan"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cleaning Data so that I can convert the fields to Datatime datatype\n",
    "\n",
    "masterDf['CLEARANCE_DATE'] = masterDf['CLEARANCE_DATE'].fillna('nan').astype(str)\n",
    "masterDf['DATE_INCIDENT_END'] = masterDf['DATE_INCIDENT_END'].fillna('nan').astype(str)\n",
    "\n",
    "def clean_text(text):\n",
    "    return text.split(' ', 1)[0] #Defining function to take only the dates and leave the times\n",
    "\n",
    "dateColumns = ['DATE_REPORTED', 'DATE_INCIDENT_BEGAN', 'DATE_INCIDENT_END','CLEARANCE_DATE']\n",
    "masterDf[dateColumns] = masterDf[dateColumns].apply(lambda x: x.apply(clean_text))\n",
    "\n",
    "masterDf[dateColumns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "397a0d19-f0bd-4540-81dc-66e3c3dc99d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 654489 entries, 0 to 654488\n",
      "Data columns (total 4 columns):\n",
      " #   Column               Non-Null Count   Dtype         \n",
      "---  ------               --------------   -----         \n",
      " 0   DATE_REPORTED        654489 non-null  datetime64[ns]\n",
      " 1   DATE_INCIDENT_BEGAN  654433 non-null  datetime64[ns]\n",
      " 2   DATE_INCIDENT_END    492793 non-null  datetime64[ns]\n",
      " 3   CLEARANCE_DATE       264798 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](4)\n",
      "memory usage: 20.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Used first for loop to ensure pandas could easily parse the dates, second for loop converts all date columns to datetime64 datatype.\n",
    "for column in dateColumns:\n",
    "    masterDf[column] = masterDf[column].str.replace('/', '-')\n",
    "for column in dateColumns:\n",
    "    masterDf[column] = pd.to_datetime(masterDf[column], errors = 'coerce')\n",
    "\n",
    "#ALl date columns have been convered to datetime64\n",
    "print(masterDf[dateColumns].info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350dbad9-14ce-485d-9138-46fa2555f52a",
   "metadata": {},
   "source": [
    "#### The metadata states that NIBRS codes in 8XXs are not considered criminal, so they will be removed from this dataframe. Metadata also states that a Clearance Status of 'Unfounded' means the report was either a false report or that no criminal activity was found, so we will drop these as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6206328-48e0-4697-9f3d-052eb8e4df39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['240', '13B', '23F', '290', '23C', '520', '26B', '26C', '90Z',\n",
       "       '35A', '23H', '13A', '100', '120', '220', '35B', '23G', '11D',\n",
       "       '26A', '280', '23D', '13C', '26F', '90B', '90D', '11A', '26G',\n",
       "       '200', '270', '26E', '99Y', '250', '370', '23B', '99Z', '36A',\n",
       "       '90J', '210', '09A', '11B', '720', '36B', '23A', '09C', '90C',\n",
       "       '90F', '90H', '40A', '90G', '90A', '09B', '64A', '23E', '11C',\n",
       "       '64B', '39C', '40B', '26D', '39A', '39B', '510', '40C'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Identifying what the 8XX codes are\n",
    "codeDf = masterDf.HIGHEST_NIBRS_CODE.unique()\n",
    "falseCodes = []\n",
    "for code in codeDf:\n",
    "    if (code[0] == '8'):\n",
    "        falseCodes.append(code)\n",
    "\n",
    "#Dropping entries where CLEARANCE_STATUS is Unfounded\n",
    "masterDf = masterDf[masterDf['CLEARANCE_STATUS'] != 'Unfounded']\n",
    "masterDf['CLEARANCE_STATUS'].value_counts() #Checking to see that 'Unfounded' is not longer in the DataFrame\n",
    "\n",
    "#Excluding entries in dataframe where the value for 'HIGHEST_NIBRS_CODE' are found in falseCodes (8XX NIBRS codes)\n",
    "masterDf = masterDf[~masterDf['HIGHEST_NIBRS_CODE'].isin(falseCodes)]\n",
    "masterDf['HIGHEST_NIBRS_CODE'].unique() #Checking to see if 8XX values are found in 'HIGHEST_NIBRS_CODE' column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2df546f-e7f6-4f30-9fbf-bdb5bae34c82",
   "metadata": {},
   "source": [
    "# **ZIP CODE WORK**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1a76a9-3ba9-49c5-b6fb-2d68abf3b6f9",
   "metadata": {},
   "source": [
    "#### Filtering Dataframe for Charlotte Zip Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61d27a83-41a8-41b1-ab81-188af38a21f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of entries before cleaning: 539334\n",
      "Number of unique zip codes before cleaning: 822\n",
      "\n",
      "\n",
      "Amount of entries after cleaning: 536490\n",
      "Number of unique zip codes after cleaning: 49\n"
     ]
    }
   ],
   "source": [
    "clt_zip_codes = ['28202', '28203', '28204', '28205', '28206', '28207', '28208', '28209', '28210', '28211', '28212', '28213',\n",
    "                 '28214', '28215', '28216', '28217', '28226', '28227', '28244', '28246', '28254', '28262', '28269', '28270',\n",
    "                 '28273', '28277', '28278', '28280', '28281', '28282', '28284', '28285', '28287', '28105', '28134', '28031', \n",
    "                 '28036', '28078']\n",
    "\n",
    "print('Amount of entries before cleaning:', masterDf.shape[0])\n",
    "print('Number of unique zip codes before cleaning:', len(dict(masterDf['ZIP'].value_counts())))\n",
    "print('\\n')\n",
    "\n",
    "masterDf['ZIP'] = masterDf['ZIP'].apply(lambda x: re.sub(r'\\D', '', str(x)))\n",
    "\n",
    "#After December of 2019, the department started entering zipcodes in the format '28223.0' as opposed to '28223'. I want these to be treated the same for analysis purposes\n",
    "#Converting zipcodes to a string and taking the first 5 elements\n",
    "masterDf['ZIP'] = masterDf['ZIP'].astype(str).str[:5]\n",
    "\n",
    "# Convert back to integers\n",
    "masterDf['ZIP'] = masterDf['ZIP'].astype(int, errors = 'ignore')\n",
    "\n",
    "#First condition filters for charlotte zip codes, second filter includes null values that will be filled later, third filter keeps values that start with '282'\n",
    "#and have a length less than 5, some zip code values in the dataframe are like '2828' or '2821', these zip codes may be charlotte zip codes but we will have to set them\n",
    "#to null and find out what they truly are in the next few functions.\n",
    "masterDf = masterDf[(masterDf['ZIP'].isin(clt_zip_codes)) | (masterDf['ZIP']=='') | ((masterDf['ZIP'].str.startswith('282')) & (masterDf['ZIP'].str.len() < 5))]\n",
    "\n",
    "print('Amount of entries after cleaning:', masterDf.shape[0])\n",
    "print('Number of unique zip codes after cleaning:', len(dict(masterDf['ZIP'].value_counts())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd81ca4-21b9-4a1a-8fa7-b7c609238a01",
   "metadata": {},
   "source": [
    "Filling null values and zip codes with length < 5 with their correct zip code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c4d6988-0df0-4e19-8c3c-0fadf0d9de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "masterDf['ZIP'] = masterDf['ZIP'].replace('', 'nan')\n",
    "\n",
    "#replacing zip codes with len<5 with a nan values to they can be filled later\n",
    "masterDf['ZIP'] = masterDf['ZIP'].apply(lambda x: x if len(str(x)) == 5 else 'nan')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e8c870-bad9-4d5d-83a2-bd632e527e50",
   "metadata": {},
   "source": [
    "### Filling null Zip Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a64d546f-7738-4f28-9422-8fecce1845ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null zip code values before filling: 168574\n"
     ]
    }
   ],
   "source": [
    "print('Number of null zip code values before filling:', masterDf['ZIP'].isin(['nan']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4da87233-9f9b-4dc7-a805-71b935176dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading GeoJSON of NC zip codes from GitHub\n",
    "\n",
    "with urlopen(\"https://raw.githubusercontent.com/OpenDataDE/State-zip-code-GeoJSON/master/nc_north_carolina_zip_codes_geo.min.json\") as response:\n",
    "    zip_codes = json.load(response)\n",
    "\n",
    "#filtering json to only include charlotte zip codes that will be used in choropleth. GeoJSON files are so big that this makes massive performance increases.\n",
    "filtered_features = [feature for feature in zip_codes['features'] if feature['properties']['ZCTA5CE10'] in clt_zip_codes]\n",
    "\n",
    "# Creates a new GeoJSON object with filtered features\n",
    "filtered_zipJSON = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": filtered_features\n",
    "}\n",
    "\n",
    "# Save filtered GeoJSON to file\n",
    "with open('charlotte_zip_json', 'w') as f:\n",
    "    json.dump(filtered_zipJSON, f)\n",
    "\n",
    "#opening new filtered GeoJSON for later use\n",
    "with open('charlotte_zip_json', 'r') as f:\n",
    "    zip_codes = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2210233-a0a5-4d51-a1d7-3671e01c4fe3",
   "metadata": {},
   "source": [
    "#### Making a dictionary where the key is the zipcode and the value is a list of coordinate points that define a charlotte zipcode. Making this dictionary will allow me to later use coordiantes to find out what zip code a crime occoured in. The GeoJSON file has coorinate points in nested lists, but I need the polygon coordinate points to be in a 1 dimensional array for the shapely function I will later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "290b7746-6212-49c7-81ff-98007ec793ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def flatten_coordinates(data):\n",
    "    flattened_data = []\n",
    "    \n",
    "    def flatten_helper(sublist):\n",
    "        for item in sublist:\n",
    "            if isinstance(item, list):\n",
    "                flatten_helper(item)\n",
    "            elif isinstance(item, (int, float)):\n",
    "                flattened_data.append(item)\n",
    "\n",
    "    flatten_helper(data)\n",
    "    tuples_data = [(flattened_data[i], flattened_data[i+1]) for i in range(0, len(flattened_data), 2)]\n",
    "    return tuples_data\n",
    "\n",
    "#initiating zip code dictionary\n",
    "zip_coords_dict={}\n",
    "\n",
    "for feature in zip_codes['features']:\n",
    "    #setting the key equal to the zipcode\n",
    "    zip_code = feature['properties']['ZCTA5CE10']\n",
    "\n",
    "    zip_coordinates = flatten_coordinates(feature['geometry']['coordinates'])\n",
    "    zip_coords_dict[zip_code]=zip_coordinates\n",
    "\n",
    "#zip_coords_dict = {key: value for key, value in zip_coords_dict.items() if key in clt_zip_codes}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babc5f28-be6e-47fb-bcb5-da525d44201b",
   "metadata": {},
   "source": [
    "#### This function takes in a longitude and latitude as inputs and uses a shapely function (which utilizes ray casting algorithm) that returns True if a point is in a polygon and False if it is not. The function loops through all of the zipcodes until it gets a true value at which point the corresponding zip code is returned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25800c99-8eac-4b8c-8981-b8ca5118e8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zipCodeFromCoords(longitude, latitude):\n",
    "    #if there is no latitude or longitude, the function does nothing\n",
    "    if not longitude or not latitude:\n",
    "        return \"nan\"\n",
    "    elif longitude and latitude:\n",
    "        \n",
    "        point = Point(longitude, latitude)\n",
    "        for zip_code_coords in list(zip_coords_dict.items()):\n",
    "            z_code = zip_code_coords[0]\n",
    "            #the coordinates of the zipcode are the values in dictionary\n",
    "            poly = Polygon(zip_code_coords[1])\n",
    "            \n",
    "            if (poly.contains(point) == True):\n",
    "                return z_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8f0f65-76f7-4d8a-a1f5-23fd9217d19a",
   "metadata": {},
   "source": [
    "### My first approach to filling null zip code values will be to use another dataset from data.charlottenc.gov that has information about 600,000+ addresses in charlotte. I can use the 'location' field in masterDf to look up the zip code in the address data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4438883-9798-4c0c-aebf-3cd9225d73e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Opening a charlotte dataset containing around 600,000 records of addresses, their zipcode, and other info. I wil be using this information\n",
    "#to reduce the amount of NaN values in the dataset\n",
    "\n",
    "AddressDF = pd.read_csv('Master_Address.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f798298e-08a9-4daf-b1e6-eabde4dc3615",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting dataframe to dictionary where key is address and zip code is the value. dictionaries will be the most efficient data structure for the task of filling blank zip codes\n",
    "\n",
    "AddressDF = AddressDF[['FullAddress', 'ZipCode']]\n",
    "AddressDF.set_index('FullAddress', inplace=True)\n",
    "AddressDict = AddressDF['ZipCode'].to_dict()\n",
    "\n",
    "#function attempts to get the zip code attached the the address but if it cannot, it keeps the value as nan\n",
    "def zipCodeGet(address):\n",
    "    ZipCode = AddressDict.get(str(address))\n",
    "\n",
    "    if ZipCode:\n",
    "        return ZipCode\n",
    "    else:\n",
    "        return \"nan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "357f82c7-cd52-4640-b1bf-8a7dd1be4506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values left after filling: 91555\n"
     ]
    }
   ],
   "source": [
    "#This block is responsible for filling all nan values of ZipCode for later use in the Choropleth map\n",
    "\n",
    "# Define a function to process each row\n",
    "def fill_from_database(row):\n",
    "    if row['ZIP'] == 'nan':\n",
    "        # Looking up the address in the database\n",
    "        zip_from_location = str(zipCodeGet(row['LOCATION']))\n",
    "        return zip_from_location\n",
    "    else:\n",
    "        return row['ZIP']\n",
    "\n",
    "# Apply the function to each row of the DataFrame\n",
    "masterDf['ZIP'] = masterDf.apply(fill_from_database, axis=1)\n",
    "\n",
    "# Count the number of remaining null values\n",
    "num_null_values = masterDf[masterDf['ZIP']=='nan'].shape[0]\n",
    "print('Number of null values left after filling:', num_null_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e358b9-2de9-4c7d-8081-559ad5f7a69b",
   "metadata": {},
   "source": [
    "### For the remaining null zip code values that could not be recovered from the address database, I will use their latitude and longitude to find out what zip code those coordiantes lie within. I will do this using the shapely library. (ZipCodeFromCoords() was defined earlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8749a163-3a2f-4e66-aab4-acbd7908ab8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values left after filling: 0\n"
     ]
    }
   ],
   "source": [
    "def process_row1(row):\n",
    "    if row['ZIP'] != 'nan':\n",
    "        return row['ZIP']\n",
    "    elif pd.isna(row['LONGITUDE_PUBLIC']) or pd.isna(row['LATITUDE_PUBLIC']):\n",
    "        return \"nan\"\n",
    "    else:\n",
    "        zip_code = str(zipCodeFromCoords(row['LONGITUDE_PUBLIC'], row['LATITUDE_PUBLIC']))\n",
    "        return zip_code\n",
    "\n",
    "# Apply the function to each row of the DataFrame\n",
    "masterDf['ZIP'] = masterDf.apply(process_row1, axis=1)\n",
    "\n",
    "# Count the number of remaining null values\n",
    "num_null_values = masterDf[masterDf['ZIP']=='nan'].shape[0]\n",
    "print('Number of null values left after filling:', num_null_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ad9fb54-ce58-4d29-91d2-780cbd7377db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean amount of days for CMPD to clear an incident is: 50 days 13:38:59.008518194 days\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TIME_TO_CLEAR\n",
       "0 days    56162\n",
       "1 days     9478\n",
       "2 days     4805\n",
       "6 days     4129\n",
       "5 days     4038\n",
       "7 days     4021\n",
       "3 days     3958\n",
       "4 days     3942\n",
       "8 days     3273\n",
       "9 days     2528\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding out how long it takes CMPD to clear an incident\n",
    "\n",
    "masterDf['TIME_TO_CLEAR'] = masterDf['CLEARANCE_DATE'] - masterDf['DATE_REPORTED']\n",
    "\n",
    "print(\"The mean amount of days for CMPD to clear an incident is: {} days\".format(masterDf['TIME_TO_CLEAR'].mean()))\n",
    "masterDf['TIME_TO_CLEAR'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66f0e94a-9a6e-4289-bba1-d9064219964b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TIME_TO_CLEAR\n",
       "True     370375\n",
       "False    166115\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterDf['TIME_TO_CLEAR'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6975fe56-b5d8-4727-ae53-9f76890df747",
   "metadata": {},
   "outputs": [],
   "source": [
    "masterDf['ZIP'] = masterDf['ZIP'].astype(str)\n",
    "zipCodeDF = masterDf[masterDf['ZIP']!='nan']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55231d73-56d6-44a3-9da5-5e273e73cc94",
   "metadata": {},
   "source": [
    "### Adding a column with the month in a number format and a column with an abbreviated month for use in dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e335c1bb-1e0c-41f4-ade3-a41c16bc7045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'MONTH' column with month numbers (1-12)\n",
    "masterDf['MONTH'] = masterDf['DATE_REPORTED'].dt.month\n",
    "\n",
    "# Add 'MONTH_NAME' column with month names\n",
    "masterDf['MONTH_NAME'] = masterDf['DATE_REPORTED'].dt.strftime('%b')\n",
    "\n",
    "month_order = \"Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\".split(\" \")\n",
    "masterDf['MONTH_NAME'] = pd.Categorical(masterDf['MONTH_NAME'], categories=month_order, ordered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e28da50-2a8b-43ea-9403-2e0a1bfc38ea",
   "metadata": {},
   "source": [
    "**Adding day of the Week Column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0dc04b1-c513-46a2-9d5d-c09ebf05d673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Saturday', 'Thursday', 'Friday', 'Monday', 'Wednesday', 'Tuesday',\n",
       "       'Sunday'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making a new column called DAY_WEEK indicating what day of the week a certain crime occoured. 0-Monday, 1-Tuesday... 6- Sunday this is for later use in a pie chart\n",
    "\n",
    "def day_of_week(num):\n",
    "    if num == 0:\n",
    "        return 'Monday'\n",
    "    elif num == 1:\n",
    "        return 'Tuesday'\n",
    "    elif num == 2:\n",
    "        return 'Wednesday'\n",
    "    elif num == 3:\n",
    "        return 'Thursday'\n",
    "    elif num == 4:\n",
    "        return 'Friday'\n",
    "    elif num == 5:\n",
    "        return 'Saturday'\n",
    "    elif num == 6:\n",
    "        return 'Sunday'\n",
    "\n",
    "masterDf['DAY_WEEK'] = masterDf['DATE_REPORTED'].apply(lambda x: x.dayofweek)\n",
    "masterDf['DAY_WEEK'] = masterDf['DAY_WEEK'].apply(day_of_week)\n",
    "\n",
    "#making sure only days of the week are in masterDf['DAY_WEEK']\n",
    "masterDf['DAY_WEEK'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d0f8ebb-0eb0-4375-a2ec-456c7f3d5f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned DataFrame to a CSV file for use in the dashboard\n",
    "masterDf.to_csv('CMPD_cleaned.csv') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
